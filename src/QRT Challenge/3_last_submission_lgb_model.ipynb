{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('data/x_train.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "x_test = pd.read_csv('data/x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train['target'] = y_train['TARGET']\n",
    "def clean_df(df, country):\n",
    "    df = df.set_index(keys='ID')\n",
    "\n",
    "    values = df[df['COUNTRY'] == country.upper()]\n",
    "    res = pd.DataFrame()\n",
    "    for c in values.columns:\n",
    "        if c[:3] == f'{country.upper()}_':\n",
    "            res[c[3:]] = values[c]\n",
    "\n",
    "    for data_c in ['GAS_RET', 'COAL_RET', 'CARBON_RET']:\n",
    "        res[data_c] = values[data_c]\n",
    "\n",
    "    if 'target' in df.columns:\n",
    "        res['target'] = df['target']\n",
    "\n",
    "    if country == 'de':\n",
    "        res['LIGNITE'] = values['DE_LIGNITE']\n",
    "\n",
    "    return res\n",
    "\n",
    "df = clean_df(x_train, 'de')\n",
    "\n",
    "# change FR_EXCHANGE to DE_EXCHANGE if country == 'fr' and viceversa\n",
    "independent_variables = ['CONSUMPTION', 'FR_EXCHANGE', 'NET_EXPORT', 'GAS', 'COAL', 'HYDRO', 'NUCLEAR', 'SOLAR', 'WINDPOW', 'RESIDUAL_LOAD', 'RAIN', 'WIND', 'TEMP', 'GAS_RET', 'COAL_RET', 'CARBON_RET']\n",
    "dependent_variables = ['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Calculate output value for ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Stratify into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quantiles(df, n):\n",
    "\n",
    "    step = 1 / n\n",
    "\n",
    "    intervals_raw = [np.quantile(df['target'], i) for i in np.arange(step, 1.0, step)]\n",
    "    intervals_ = [float('-inf')] + intervals_raw + [float('inf')]\n",
    "\n",
    "\n",
    "    intervals = dict()\n",
    "\n",
    "    for b_val, t_val in zip(intervals_, intervals_[1:]):\n",
    "        indices = np.where(np.logical_and(df['target'] > b_val, df['target'] <= t_val))\n",
    "        interval_mean = round(df['target'].iloc[indices].mean(), 3)\n",
    "        intervals[interval_mean] = b_val, t_val\n",
    "    \n",
    "    return intervals\n",
    "\n",
    "\n",
    "\n",
    "def discretize_df(df,n):\n",
    "        for index, value in df['target'].items():\n",
    "            for disc, (b_range, t_range) in generate_quantiles(df,n).items():\n",
    "                if b_range < value <= t_range:\n",
    "                    df.loc[index, 'disc_target'] = disc\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV for parameter hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3456 candidates, totalling 17280 fits\n",
      "Best Hyperparameters: {'bagging_fraction': 0.5, 'boosting_type': 'dart', 'learning_rate': 0.05, 'max_bin': 20, 'max_depth': 10, 'min_data_in_leaf': 30, 'min_sum_hessian_in_leaf': 100.0, 'num_leaves': 50, 'objective': 'mae', 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# might take a while\n",
    "# ----------------------\n",
    "param_grid = {\n",
    "    'objective': ['mape', 'mae'],\n",
    "    'boosting_type': ['gbdt', 'dart'],  \n",
    "    'bagging_fraction': [0.5, 0.7],\n",
    "    'learning_rate': [0.1, 0.05],\n",
    "    'max_bin': [20, 25, 30],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_data_in_leaf': [30, 40, 50],\n",
    "    'min_sum_hessian_in_leaf': [50, 100.0],\n",
    "    'num_leaves': [50, 75],\n",
    "    'subsample': [0.5, 0.2],\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(verbose=-1, is_unbalance=True, boost_from_average=False)\n",
    "\n",
    "grid_search = GridSearchCV(lgb_model, param_grid, scoring='neg_mean_absolute_percentage_error', cv=5, verbose=1)\n",
    "\n",
    "grid_search.fit(df[independent_variables],df['target']) \n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate model performance by iteratively fit the model on different validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman: 0.5163865836389324, Pearson: 0.29238692063635807\n",
      "Spearman: 0.42173445742527554, Pearson: 0.37718516091837845\n",
      "Spearman: 0.43171243013582344, Pearson: 0.2826871855933726\n",
      "Spearman: 0.36811153259466406, Pearson: 0.35107481107632094\n",
      "Spearman: 0.4754605832783587, Pearson: 0.38410025769416084\n",
      "Spearman: 0.37011530092551786, Pearson: 0.21278716335651993\n",
      "Spearman: 0.46064808397822987, Pearson: 0.3684393966059429\n",
      "Spearman: 0.44252836935411044, Pearson: 0.3578060855814162\n",
      "Spearman: 0.4461626294882926, Pearson: 0.33885870386743133\n",
      "Spearman: 0.5057840068365139, Pearson: 0.34085322345274144\n",
      "Spearman: 0.437620955153927, Pearson: 0.40947807960083143\n",
      "Spearman: 0.3636387836077498, Pearson: 0.18900686063377586\n",
      "Spearman: 0.31627480795756496, Pearson: 0.21460506323581408\n",
      "Spearman: 0.4929285714185081, Pearson: 0.3406725161933845\n",
      "Spearman: 0.44385210131101616, Pearson: 0.2734997420909929\n",
      "Spearman: 0.5640968571903996, Pearson: 0.41318504078315776\n",
      "Spearman: 0.5533298581136771, Pearson: 0.38175735584342946\n",
      "Spearman: 0.4527784839957951, Pearson: 0.3203891199432631\n",
      "Spearman: 0.5151533313171562, Pearson: 0.35898264697310855\n",
      "Spearman: 0.4723513078753249, Pearson: 0.31787564983751143\n",
      "Spearman: 0.47161046464970197, Pearson: 0.37501817031335155\n",
      "Spearman: 0.5667063639803297, Pearson: 0.34836755701219463\n",
      "Spearman: 0.3971707044836055, Pearson: 0.2468907054522442\n",
      "Spearman: 0.513343310289563, Pearson: 0.3030388905806531\n",
      "Spearman: 0.5861466488142637, Pearson: 0.31316295706054004\n",
      "Spearman: 0.5383410382536816, Pearson: 0.39308796822618286\n",
      "Spearman: 0.33799673004946595, Pearson: 0.21317691995632998\n",
      "Spearman: 0.42114560480924623, Pearson: 0.2860808954159991\n",
      "Spearman: 0.5466799883261899, Pearson: 0.3376052532325545\n",
      "Spearman: 0.5626035545838174, Pearson: 0.38473461294977856\n",
      "0.4664137814612234\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_params['verbose'] = -1\n",
    "best_params['is_unbalance'] = True\n",
    "best_params['boost_from_average'] = False\n",
    "\n",
    "n = 30\n",
    "res = []\n",
    "for i in range(n):\n",
    "\n",
    "    \n",
    "    discretize_df(df, 12)\n",
    "\n",
    "    train, test = train_test_split(df, test_size=0.2, stratify=df['disc_target'])\n",
    "    train_d = lgb.Dataset(df[independent_variables], label = df['target'])\n",
    "    test_d = lgb.Dataset(df[independent_variables], label = df['target']) \n",
    "\n",
    "\n",
    "\n",
    "    num_boost_round = 20  # Keep low to prevent overfitting\n",
    "    model = lgb.train(best_params, train_d, num_boost_round=num_boost_round)\n",
    "\n",
    "    outputs = model.predict(test[independent_variables], num_iteration=model.best_iteration)\n",
    "\n",
    "\n",
    "    from scipy.stats import spearmanr\n",
    "\n",
    "    spearman_ = spearmanr(outputs, test['target']).correlation\n",
    "    pearson_ = np.corrcoef(outputs,  test['target'])[0,1]\n",
    "    res.append(spearman_)\n",
    "\n",
    "    print(f'Spearman: {spearman_}, Pearson: {pearson_}')\n",
    "\n",
    "\n",
    "# Average spearman correlation over n fits\n",
    "print(np.mean(res))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "This notebook shows the model for Germany only. We used different parameters for France but since we were in a rush, so we did not store them.\n",
    "\n",
    "\n",
    "## Takeaways\n",
    "- CVGridSearch can be further optimized by sampling the uniform distribution\n",
    "- Increasing the number of boosting iterations will overfit the model for this dataset\n",
    "- Low learning rates will get the model stuck in a local minimum\n",
    "\n",
    "## Further Improvements\n",
    "- Try to add lags of the most significant predictors\n",
    "- It can be interesting to use unsupervised learning to cluster the data and try to use cluster labels as predictors\n",
    "- Using both models and take the average might lead to a more generalized model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
